{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Librabries\n",
    "First, Import Libraries such as Numpy and Pandas for Data cleaning and Manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "For this Project, We are using a small dataset which consists information on people applying for jobs.Load the dataset using the pandas method pd.read_csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = pd.read_csv('OneDrive\\Desktop\\Week 3 - Data Cleaning (Pandas) - 1\\Data-cleaning-for-beginners-using-pandas.csv')\n",
    "print(Dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Values\n",
    "Now, After Loading the Dataset we have to check for the missing values and deal with them. Generally, If the dataset is large we remove the missing or Null values from the dataset but In this case the dataset is quite small so instead of removing them we have to deal with them in another way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As there are 7 missing values in age column, we can impute the missing values with the help of mean or median.First,We have to convert the age column into numeric format then we can calculate the median of the age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['Age'] = pd.to_numeric(Dataset['Age'],errors='coerce')\n",
    "median_age = Dataset['Age'].median()\n",
    "Dataset['Age'].fillna(median_age,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning / Transformation\n",
    "Now, As you can see that the Salary column have a very inconsistent format so we have to perform some standardization and formatting.The current format appears to include dollar signs ('$'), 'k' for thousands, and a range specified as \"low-high\". We can change the range representation of salary into average of that range so that we can perform a consistent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['Salary'] = Dataset['Salary'].replace({'\\$': '', 'k': '000', '-': '-'},regex=True)\n",
    "def calculate_average_salary(Salary):\n",
    "    if isinstance(Salary, str) and '-' in Salary:\n",
    "        lower, upper = map(float, Salary.split('-'))\n",
    "        return (lower + upper) / 2\n",
    "    return Salary\n",
    "Dataset['Salary'] = Dataset['Salary'].apply(calculate_average_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, If we look at the location column we can see inconsistency with location name like there are some spaces between Name and the abbreviation, some comma between name and abbreviations. This create problem when doing the analysis so it's better to remove the white spaces, comma's , abbreviations so that all the values becomes consistent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['Location'] = Dataset['Location'].str.replace(',', '').str.strip()\n",
    "abbreviations_to_remove = ['In', 'Ny', 'Aus']\n",
    "for abbreviation in abbreviations_to_remove:\n",
    "     Dataset['Location'] = Dataset['Location'].apply(lambda x: x[:-len(abbreviation)] if x.endswith(abbreviation) else x).str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rating column consists of rating of the company out of 10 but if we look at the entries there are some entries with the values '-1' which does not any sense because there are no rating below 0 so we can assume that '-1' depicts that the ratings for these companies are not available. Droping these entries will affect the analysis because of the size of dataset. We can replace these values with the mean or median of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rating = Dataset['Rating'].median()\n",
    "Dataset['Rating'].replace(-1,median_rating,inplace=True)\n",
    "Dataset['Rating'].fillna(median_rating,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Established year column have some entries with values '-1' as well but we can not replace with mean or median because the values are years format so we can assume that the establishment year of these companies are not available so '-1' are used as placeholders. We can replace these values with 'Not available'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['Established'].replace(-1,'Not available',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy Apply column is a boolean type so all the values are in True and False so we can assume that the entries with the values '-1' are False. We can simply replace the '-1' values with False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['Easy Apply'] = Dataset['Easy Apply'].replace([-1, '-1', 'Not Available', 'Not Applicable', 'False'], False, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Outliers\n",
    "Now, We have to check for the outliers in columns like Age, Rating, Salary because extreme low or high values might affect our analysis. So we have to make sure that all the values are lies with specific range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=Dataset['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the outliers in 'Salary' column by calcualting the z-score. If the values corresponds false that means it is not a outlier but if it is true then it is a outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "z_scores = zscore(Dataset['Salary'])\n",
    "outliers = (z_scores > 3) | (z_scores < -3)\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
